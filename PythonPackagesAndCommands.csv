DataFrame
	.index
	.values
	.shape
	.dtypes
	.columns
	.axes ()combination of index and columns
	.get_dtype_counts()
	.info()
	.drop(columns=['B', 'C']) #dropping columns B and C
	

Reading csv
	pd.read_csv('employees.csv',parse_dates=["Start Date","Last Login Time"])

Conversions
	df[<columnName>].astype("int" or category or bool)
	pd.to_datetime(df[<columnName>],format='%Y-%m-%d %H:%M:%S')

Handling Null values
	.dropna() #drop rows having any null values
	.dropna(how='all').tail() #drop rows having all values as null and display tail
	.dropna(how='all',inplace=True)
	.dropna(axis = 1) #drop columns having any null values
	.dropna(subset=['Salary']) #Checks only salary column for null values
	.fillna(0) #not much usefull as it will replace all NaN with 0
	df['Salary'].fillna(0,inplace=True)
	df.isnull().any() #Check is any columm contains null values
	
Checking Missing values
	missing_df = train_df.isnull().sum(axis=0).reset_index()
	missing_df.columns = ['column_name', 'missing_count']
	missing_df = missing_df[missing_df['missing_count']>0]
	missing_df = missing_df.sort_values(by='missing_count')
	missing_df
	
Columns with constant values
	unique_df = train_df.nunique().reset_index()
	unique_df.column = ['col_name','unique_count']
	constant_df = unique_df[unique_df['unique_count']==1]
	constant_df.shape

Filtering
	df[(mask1 & mask2) | mask3]
	df[<columnName>].isin(["Legal","Sales","Product"])
	df[<columnName>].isnull()
	df[<columnName>].notnull()
	
Sorting and Ranking
	.sort_values(by='Name',ascending=False)
	.sort_index(inplace=True)
	df['Salary'].rank(ascending=False).astype('int')
	
Merging, aggregation
	.groupby(['item_nbr','store_nbr']).agg({'unit_sales':'mean'})
	To find unique values and there counts
		.groupby("<columnforuniquevalues>")["indexcolumn"].nunique()
		df_train["onpromotion"].value_counts()
		
Finding Pearson or spearman correlation
	from scipy.stats import spearmanr,pearsonr
	values.append(spearmanr(df_train[col].values,df_train["medv"].values)[0])
	spr = spearmanr(x, y).correlation
	pcr = np.corrcoef(x, y)[0, 1]
Rows of one column not present in another column
	1. df[-df["column"].isin(["value"])]
	2. df[~df["column"].isin(["value"])]
	3. df[df["column"].isin(["value"]) == False]
	4. df[np.logical_not(df["column"].isin(["value"]))]

Creating ordinal variable
	heads['floor'] = np.argmax(np.array(heads[['eviv1', 'eviv2', 'eviv3']]),axis = 1) # np.argmax returns the indices of maximum value along an axis
	
Packages
	xlrd
	openpyxl
	pip install graphviz (visualizing decision trees)
	conda install -c conda-forge hyperopt (for model hyperparameter optimization)
	conda install -c conda-forge lightgbm
	conda install -c conda-forge umap-learn (dimention reduction)
	conda install -c conda-forge fbprophet (Prophet package for time series modelling)
	
	
	
Widgets
	conda install -c conda-forge ipywidgets
	jupyter nbextension enable --py --sys-prefix widgetsnbextension
	
Extensions
https://codeburst.io/jupyter-notebook-tricks-for-data-science-that-enhance-your-efficiency-95f98d3adee4
https://ndres.me/post/best-jupyter-notebook-extensions/
	