{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#FA8072\">Corporaci√≥n Favorita Grocery Sales Forecasting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#FA8072\">Importing Libraries<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#FA8072\">Reading Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderPath = \"D:\\Competitions\\CorporationGrocerySalesPrediction\"\n",
    "folderTemp = \"D:\\Competitions\\CorporationGrocerySalesPrediction\\temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = \"train.csv\"\n",
    "filePath = os.path.join(folderPath,fileName)\n",
    "types = {\n",
    "    'item_nbr':np.uint16,\n",
    "    'store_nbr':np.uint8,\n",
    "    'unit_sales':np.float32,\n",
    "    'onpromotion':'object'\n",
    "}\n",
    "df_train = pd.read_csv(filePath\n",
    "                   ,usecols=['store_nbr','date','item_nbr','unit_sales','onpromotion']\n",
    "                   ,dtype=types\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['onpromotion'] = df_train['onpromotion'].fillna(2)\n",
    "df_train['onpromotion'] = df_train['onpromotion'].replace('True',1)\n",
    "df_train['onpromotion'] = df_train['onpromotion'].replace('False',0)\n",
    "df_train[\"onpromotion\"] = df_train[\"onpromotion\"].astype(np.int8)\n",
    "df_train[\"date\"] =  pd.to_datetime(df_train[\"date\"],format=\"%Y-%m-%d\",exact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 125497040\n",
      "ColumnNames: ['date' 'store_nbr' 'item_nbr' 'unit_sales' 'onpromotion']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\",len(df_train))\n",
    "print(\"ColumnNames:\",df_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFileName = \"test.csv\"\n",
    "storeFileName = \"stores.csv\"\n",
    "holidayFileName = \"holidays_events.csv\"\n",
    "transactionFileName = \"transactions.csv\"\n",
    "itemFileName = \"items.csv\"\n",
    "oilFileName = \"oil.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = {\n",
    "    'id':np.uint32,\n",
    "    'item_nbr':np.uint16,\n",
    "    'store_nbr':np.uint8,\n",
    "    'onpromotion':'object'\n",
    "}\n",
    "test = pd.read_csv(os.path.join(folderPath,testFileName)\n",
    "                   ,usecols=['id','store_nbr','date','item_nbr','onpromotion']\n",
    "                   ,dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['onpromotion'] = test['onpromotion'].fillna(2)\n",
    "test['onpromotion'] = test['onpromotion'].replace('True',1)\n",
    "test['onpromotion'] = test['onpromotion'].replace('False',0)\n",
    "test[\"onpromotion\"] = test[\"onpromotion\"].astype(np.int8)\n",
    "test[\"date\"] =  pd.to_datetime(test[\"date\"],format=\"%Y-%m-%d\",exact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filePath = os.path.join(folderPath,storeFileName)\n",
    "stores = pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores[\"store_nbr\"] = stores[\"store_nbr\"].astype(np.int8)\n",
    "stores[\"type\"] = stores[\"type\"].astype(\"category\")\n",
    "stores[\"cluster\"] = stores[\"cluster\"].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filePath = os.path.join(folderPath,holidayFileName)\n",
    "holidays = pd.read_csv(filePath)\n",
    "holidays[\"date\"] = pd.to_datetime(holidays.date,format=\"%Y-%m-%d\",exact=True)\n",
    "holidays[\"transferred\"] = holidays[\"transferred\"].astype(np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'type', 'locale', 'locale_name', 'description', 'transferred'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "National    174\n",
       "Local       152\n",
       "Regional     24\n",
       "Name: locale, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(holidays.columns)\n",
    "holidays[\"locale\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#picking holidays where day was off\n",
    "holidays = holidays.loc[(holidays.type!='Event') & (holidays.type!='Work Day') & (holidays.transferred == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays.drop([\"type\",\"description\",\"transferred\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Items Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filePath = os.path.join(folderPath,itemFileName)\n",
    "items = pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_nbr', 'family', 'class', 'perishable'], dtype='object')\n",
      "33\n",
      "337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "iinfo(min=-32768, max=32767, dtype=int16)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(items.columns)\n",
    "print(items.family.nunique())\n",
    "print(items[\"class\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items[\"item_nbr\"] = items[\"item_nbr\"].astype(np.uint16)\n",
    "items[\"class\"] = items[\"class\"].astype(np.uint16)\n",
    "items[\"perishable\"] = items[\"perishable\"].astype(np.uint8)\n",
    "items[\"family\"] = items[\"family\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4100 entries, 0 to 4099\n",
      "Data columns (total 4 columns):\n",
      "item_nbr      4100 non-null uint16\n",
      "family        4100 non-null category\n",
      "class         4100 non-null uint16\n",
      "perishable    4100 non-null uint8\n",
      "dtypes: category(1), uint16(2), uint8(1)\n",
      "memory usage: 25.6 KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#FA8072\">Data Values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    96028767\n",
       "2    21657651\n",
       "1     7810622\n",
       "Name: onpromotion, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"onpromotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit Sales smaller than zero: 7795\n"
     ]
    }
   ],
   "source": [
    "print('Unit Sales smaller than zero:', (df_train[\"unit_sales\"]<0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max date: 2017-08-15 00:00:00 Min date: 2013-01-01 00:00:00\n",
      "Unique Stores: 54 Unique Items: 3924\n"
     ]
    }
   ],
   "source": [
    "print(\"Max date:\",df_train[\"date\"].max(),\"Min date:\",df_train[\"date\"].min())\n",
    "print(\"Unique Stores:\",len(df_train[\"store_nbr\"].unique()),\"Unique Items:\",len(df_train[\"item_nbr\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125497040 entries, 0 to 125497039\n",
      "Data columns (total 5 columns):\n",
      "date           datetime64[ns]\n",
      "store_nbr      uint8\n",
      "item_nbr       uint16\n",
      "unit_sales     float32\n",
      "onpromotion    int8\n",
      "dtypes: datetime64[ns](1), float32(1), int8(1), uint16(1), uint8(1)\n",
      "memory usage: 1.9 GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3171867\n",
      "1     198597\n",
      "Name: onpromotion, dtype: int64\n",
      "Max date: 2017-08-31 00:00:00 Min date: 2017-08-16 00:00:00\n",
      "Unique Stores: 54 Unique Items: 256\n"
     ]
    }
   ],
   "source": [
    "print(test[\"onpromotion\"].value_counts())\n",
    "print(\"Max date:\",test[\"date\"].max(),\"Min date:\",test[\"date\"].min())\n",
    "print(\"Unique Stores:\",len(test[\"store_nbr\"].unique()),\"Unique Items:\",len(test[\"item_nbr\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=\"#FA8072\">Data Preprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_dates = df_train.date.unique()\n",
    "u_stores = df_train.store_nbr.unique()\n",
    "u_items = df_train.item_nbr.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "cannot handle a non-unique multi-index!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-a8ccdda0844b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     pd.MultiIndex.from_product(\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mu_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_stores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'store_nbr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'item_nbr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2933\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2934\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2935\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reindex_axis'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[1;32m-> 3023\u001b[1;33m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[0;32m   3024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2869\u001b[0m             frame = frame._reindex_index(index, method, copy, level,\n\u001b[1;32m-> 2870\u001b[1;33m                                          fill_value, limit, tolerance)\n\u001b[0m\u001b[0;32m   2871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2872\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   2876\u001b[0m         new_index, indexer = self.index.reindex(new_index, method=method,\n\u001b[0;32m   2877\u001b[0m                                                 \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m                                                 tolerance=tolerance)\n\u001b[0m\u001b[0;32m   2879\u001b[0m         return self._reindex_with_indexers({0: [new_index, indexer]},\n\u001b[0;32m   2880\u001b[0m                                            \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   1900\u001b[0m                                                tolerance=tolerance)\n\u001b[0;32m   1901\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1902\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot handle a non-unique multi-index!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1904\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: cannot handle a non-unique multi-index!"
     ]
    }
   ],
   "source": [
    "df_train.set_index(['date', 'store_nbr', 'item_nbr'], inplace=True)\n",
    "df_train = df_train.reindex(\n",
    "    pd.MultiIndex.from_product(\n",
    "        (u_dates, u_stores, u_items),\n",
    "        names=['date','store_nbr','item_nbr']\n",
    "    )\n",
    ")\n",
    "del u_dates, u_stores, u_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#FA8072\">Merging Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### holidays and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueStores = stores.store_nbr.unique()\n",
    "uniqueHolidays = holidays.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store = pd.DataFrame(columns=[\"store_nbr\",\"holiday\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for store in uniqueStores:\n",
    "    for holiday in uniqueHolidays:\n",
    "        holiday_store = holiday_store.append(pd.DataFrame({'store_nbr':store,'holiday':holiday},index=[0]),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del uniqueHolidays,uniqueStores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store[\"holiday\"] = pd.to_datetime(holiday_store.holiday,format=\"%Y-%m-%d\",exact=True)\n",
    "holiday_store[\"store_nbr\"] = holiday_store[\"store_nbr\"].astype(np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store = holiday_store.merge(holidays,how=\"left\",left_on='holiday',right_on=\"date\").drop(\"date\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store = holiday_store.merge(stores,how=\"left\",left_on='store_nbr',right_on=\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del stores,holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store.dayoff = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def holiday_estimator(row):\n",
    "    if row.locale == 'National':\n",
    "        return 1\n",
    "    elif row.locale == \"Regional\":\n",
    "        if row.state == row.locale_name:\n",
    "            return 1 \n",
    "    else:\n",
    "        if row.city == row.locale_name:\n",
    "            return 1\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store[\"dayoff\"] = holiday_store.apply(holiday_estimator,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store.drop([\"locale\",\"locale_name\",'state','city'],axis=1,inplace=True)\n",
    "holiday_store[\"dayoff\"] = holiday_store[\"dayoff\"].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store.to_csv(os.path.join(folderPath,\"holiday_store.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holidays store and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.merge(holiday_store,how=\"left\",left_on=[\"date\",\"store_nbr\"],right_on=[\"holiday\",\"store_nbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9233"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
